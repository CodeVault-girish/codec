{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install -U speechtokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ZhangXInFD/SpeechTokenizer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cd SpeechTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install beartype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from speechtokenizer import SpeechTokenizer\n",
    "import torchaudio\n",
    "import torch\n",
    "config_path = '../model_/speechtokenizer_hubert_avg_config.json'\n",
    "ckpt_path = '../model_/SpeechTokenizer.pt'\n",
    "model = SpeechTokenizer.load_from_checkpoint(config_path, ckpt_path)\n",
    "wav, sr = torchaudio.load('../../1001_DFA_ANG_XX.wav')\n",
    "\n",
    "if wav.shape[0] > 1:\n",
    "    wav = wav[:1, :]\n",
    "\n",
    "if sr != model.sample_rate:\n",
    "    wav = torchaudio.functional.resample(wav, sr, model.sample_rate)\n",
    "\n",
    "wav = wav.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    codes = model.encode(wav)\n",
    "\n",
    "RVQ_1 = codes[:1, :, :] \n",
    "RVQ_supplement = codes[1:, :, :] \n",
    "\n",
    "# Take averages of RVQ_1 and RVQ_supplement\n",
    "RVQ_1_avg = RVQ_1.squeeze().float().mean(dim=0)\n",
    "RVQ_supplement_avg = RVQ_supplement.squeeze().float().mean(dim=0)\n",
    "\n",
    "# Combine both averages\n",
    "final_avg = (RVQ_1_avg + RVQ_supplement_avg) / 2\n",
    "print(final_avg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from speechtokenizer import SpeechTokenizer\n",
    "\n",
    "folder_path = \"/kaggle/input/emodb-crema-d/EmoDb/wav\"\n",
    "output_file = \"/kaggle/working/SpeechTokenizer_EmoDb.csv\" \n",
    "\n",
    "# download the model from github and put the path of .json and .pt \n",
    "\n",
    "config_path = '/kaggle/input/model/speechtokenizer_hubert_avg_config.json'\n",
    "ckpt_path = '/kaggle/input/model/SpeechTokenizer.pt'\n",
    "model = SpeechTokenizer.load_from_checkpoint(config_path, ckpt_path).eval()\n",
    "\n",
    "def preprocess_audio(audio_path, target_sample_rate):\n",
    "    try:\n",
    "        # Load waveform\n",
    "        waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "        # Ensure mono channel\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform[:1, :]\n",
    "\n",
    "        # Resample if necessary\n",
    "        if sample_rate != target_sample_rate:\n",
    "            waveform = torchaudio.functional.resample(waveform, sample_rate, target_sample_rate)\n",
    "\n",
    "        # Add batch dimension\n",
    "        return waveform.unsqueeze(0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file {audio_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_features(audio_path, model):\n",
    "    target_sample_rate = model.sample_rate\n",
    "    audio = preprocess_audio(audio_path, target_sample_rate)\n",
    "    if audio is None:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Encode and separate codes\n",
    "        with torch.no_grad():\n",
    "            codes = model.encode(audio)\n",
    "\n",
    "        RVQ_1_avg = codes[:1, :, :].squeeze().float().mean(dim=0)\n",
    "        RVQ_supplement_avg = codes[1:, :, :].squeeze().float().mean(dim=0)\n",
    "\n",
    "        final_avg = (RVQ_1_avg + RVQ_supplement_avg) / 2\n",
    "        return final_avg.cpu().numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "all_features = []\n",
    "filenames = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_features(file_path, model)\n",
    "        if features is not None:\n",
    "            # Append features and filename to the lists\n",
    "            all_features.append(features)\n",
    "            filenames.append(filename)\n",
    "\n",
    "features_df = pd.DataFrame(all_features)\n",
    "features_df.insert(0, 'filename', filenames)  # Insert filename column at the beginning\n",
    "\n",
    "features_df.to_csv(output_file, index=False)\n",
    "print(f\"Saved all features to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
